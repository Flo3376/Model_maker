"""
Workers audio pour NovaQA
G√®re l'enregistrement, la lecture et le monitoring audio
"""

import os
import math
import queue
import time
import numpy as np
import sounddevice as sd
import soundfile as sf
import pygame
from PyQt6.QtCore import QObject, QThread, QTimer, pyqtSignal

from .config import (
    DBFS_FLOOR, UPDATE_INTERVAL_MS, BLOCKSIZE, DTYPE,
    VU_METER_THRESHOLD, SPEECH_START_THRESHOLD_SEC, SPEECH_SILENCE_TIMEOUT_MS,
    SPEECH_TOLERANCE_MS, RESPONSE_SAMPLE_RATE, RESPONSE_FOLDER, AMBIANCE_VOLUME,
    IMMEDIATE_RECORDING, NOISE_FLOOR_ADAPTATION, NOISE_FLOOR_LEARNING_SEC,
    DYNAMIC_SILENCE_DETECTION, MIN_SILENCE_DURATION_MS
)
from .environment_utils import environment_manager


class AudioWorker(QObject):
    """Worker audio simplifi√©"""
    level = pyqtSignal(float)

    def __init__(self):
        super().__init__()
        self.device_index = None
        self._stream = None
        self._q = queue.Queue(maxsize=8)
        self._timer = QTimer()
        self._timer.timeout.connect(self._process_queue)
        self._timer.start(UPDATE_INTERVAL_MS)

    def _audio_callback(self, indata, frames, time, status):
        try:
            data = np.mean(indata.astype(np.float32), axis=1)
            try:
                self._q.put_nowait(data.copy())
            except queue.Full:
                pass
        except Exception as e:
            print(f"Erreur callback: {e}")

    def _process_queue(self):
        try:
            if self._q.empty():
                return
            buf = []
            while not self._q.empty():
                try:
                    buf.append(self._q.get_nowait())
                except queue.Empty:
                    break
            if not buf:
                return
            x = np.concatenate(buf)
            rms = float(np.sqrt(np.mean(np.square(x), dtype=np.float64)))
            if rms <= 1e-9 or not np.isfinite(rms):
                dbfs = -math.inf
            else:
                dbfs = 20.0 * math.log10(rms)
                dbfs = max(DBFS_FLOOR, min(0.0, dbfs))
            self.level.emit(dbfs)
        except Exception as e:
            print(f"Erreur process_queue: {e}")

    def is_running(self) -> bool:
        return self._stream is not None

    def start(self):
        try:
            self.stop()
            if self.device_index is None:
                return
            dev_info = sd.query_devices(self.device_index)
            sr = dev_info.get('default_samplerate', 48000) or 48000
            ch = min(1, max(1, dev_info.get('max_input_channels', 1)))
            self._stream = sd.InputStream(
                device=self.device_index,
                channels=ch,
                samplerate=sr,
                blocksize=BLOCKSIZE,
                dtype=DTYPE,
                callback=self._audio_callback,
            )
            self._stream.start()
        except Exception as e:
            print(f"Erreur start stream: {e}")

    def stop(self):
        if self._stream is not None:
            try:
                self._stream.stop()
                self._stream.close()
            except Exception:
                pass
            finally:
                self._stream = None


class ResponseRecorder(QThread):
    """Enregistreur de r√©ponse avec d√©tection automatique de d√©but/fin de parole"""
    recording_started = pyqtSignal()
    recording_finished = pyqtSignal(str)  # √âmet le chemin du fichier enregistr√©
    speech_detected = pyqtSignal()
    silence_detected = pyqtSignal()
    
    def __init__(self, question_number, device_index=None):
        super().__init__()
        self.question_number = question_number
        self.device_index = device_index
        self.should_stop = False
        
        # √âtat de l'enregistrement
        self.recording_active = IMMEDIATE_RECORDING  # D√©marrer imm√©diatement si configur√©
        self.speech_started = IMMEDIATE_RECORDING    # Idem
        self.last_activity_time = None
        self.last_silence_time = None
        self.silence_start_time = None
        self.recording_data = []
        
        # Gestion environnement bruyant
        self.noise_floor = -60.0  # Plancher de bruit initial (sera appris)
        self.noise_samples = []   # √âchantillons pour apprentissage du bruit
        self.learning_phase = NOISE_FLOOR_ADAPTATION
        self.learning_start_time = None
        self.dynamic_threshold = VU_METER_THRESHOLD
        
    def run(self):
        try:
            # Pr√©parer le fichier de sortie
            output_file = f"{RESPONSE_FOLDER}/reponse_{self.question_number:02d}.wav"
            os.makedirs(RESPONSE_FOLDER, exist_ok=True)
            
            print(f"üé§ D√©marrage surveillance r√©ponse Q{self.question_number}")
            print(f"   üìÅ Fichier: {output_file}")
            if IMMEDIATE_RECORDING:
                print(f"   üöÄ ENREGISTREMENT IMM√âDIAT activ√©")
                print(f"   ü§´ Timeout silence: {MIN_SILENCE_DURATION_MS}ms (optimis√© r√©ponses courtes)")
            else:
                print(f"   ‚è±Ô∏è Seuil d√©marrage: {SPEECH_START_THRESHOLD_SEC}s d'activit√©")
                print(f"   ü§´ Timeout silence: {SPEECH_SILENCE_TIMEOUT_MS}ms")
            
            if NOISE_FLOOR_ADAPTATION:
                print(f"   üîá Adaptation au bruit ambiant: {NOISE_FLOOR_LEARNING_SEC}s d'apprentissage")
            
            # Configuration audio optimis√©e pour qualit√©
            if self.device_index is None:
                return
                
            # Forcer 44.1kHz pour √©viter les probl√®mes de resampling
            samplerate = RESPONSE_SAMPLE_RATE  # Toujours 44100, pas de device auto
            channels = 1  # Mono pour les r√©ponses
            
            print(f"   üéöÔ∏è Audio config: {samplerate}Hz, {channels}ch, blocksize={BLOCKSIZE}")
            
            def audio_callback(indata, frames, time_info, status):
                if self.should_stop:
                    raise sd.CallbackStop()
                
                # V√©rifier les erreurs de status
                if status:
                    print(f"‚ö†Ô∏è Audio callback status: {status}")
                
                # Utiliser directement float32 sans conversion multiple
                audio_data = indata.astype(np.float32)
                
                # Calculer le niveau audio (RMS puis dBFS) de mani√®re optimis√©e
                rms = np.sqrt(np.mean(audio_data ** 2))
                if rms > 1e-10:  # √âviter log(0)
                    dbfs = 20.0 * np.log10(rms)
                    dbfs = np.clip(dbfs, -80.0, 0.0)  # Plus efficace que max/min
                else:
                    dbfs = -80.0
                
                self._process_audio_level(dbfs, audio_data, frames)
            
            # D√©marrer le stream d'enregistrement avec param√®tres optimis√©s
            with sd.InputStream(
                device=self.device_index,
                channels=channels,
                samplerate=samplerate,
                callback=audio_callback,
                blocksize=BLOCKSIZE,
                dtype=DTYPE,
                latency='low',        # Latence faible pour r√©duire les hachures
                extra_settings=sd.WasapiSettings(exclusive=False)  # Mode partag√© plus stable
            ):
                if IMMEDIATE_RECORDING:
                    print("üî¥ ENREGISTREMENT D√âMARR√â IMM√âDIATEMENT")
                    print("üé§ Parlez maintenant, la d√©tection de fin est automatique")
                    self.recording_started.emit()
                    self.speech_detected.emit()
                else:
                    print("üé§ Stream d'enregistrement actif, en attente de parole...")
                
                # Attendre jusqu'√† arr√™t
                while not self.should_stop:
                    self.msleep(50)
            
            # Sauvegarder l'enregistrement si on a des donn√©es
            if self.recording_data:
                self._save_recording(output_file, samplerate)
                
        except Exception as e:
            print(f"‚ùå Erreur enregistrement r√©ponse: {e}")
    
    def _process_audio_level(self, dbfs, indata, frames):
        """Traite le niveau audio pour d√©tecter d√©but/fin de parole avec gestion du bruit"""
        current_time = time.time()
        
        # Phase d'apprentissage du bruit de fond
        if self.learning_phase and NOISE_FLOOR_ADAPTATION:
            if self.learning_start_time is None:
                self.learning_start_time = current_time
                print(f"üîá D√©but apprentissage bruit de fond...")
            
            learning_duration = current_time - self.learning_start_time
            if learning_duration < NOISE_FLOOR_LEARNING_SEC:
                # Collecter √©chantillons de bruit
                self.noise_samples.append(dbfs)
                return  # Ne pas traiter pendant l'apprentissage
            else:
                # Finir apprentissage
                if self.noise_samples:
                    self.noise_floor = np.percentile(self.noise_samples, 75)  # 75√®me percentile
                    
                    # Auto-configuration selon l'environnement d√©tect√©
                    env_type = environment_manager.auto_configure(self.noise_samples)
                    self.dynamic_threshold = environment_manager.get_adapted_threshold(self.noise_floor)
                    
                    print(f"‚úÖ Bruit de fond appris: {self.noise_floor:.1f} dBFS")
                    print(f"üìä Nouveau seuil adaptatif: {self.dynamic_threshold:.1f} dBFS")
                    print(f"üéØ Environnement d√©tect√©: {env_type}")
                else:
                    print("‚ö†Ô∏è Pas d'√©chantillons de bruit, utilisation seuil par d√©faut")
                    self.dynamic_threshold = VU_METER_THRESHOLD
                
                self.learning_phase = False
                self.noise_samples = []  # Lib√©rer m√©moire
        
        # Utiliser le seuil adaptatif ou fixe
        threshold = self.dynamic_threshold if DYNAMIC_SILENCE_DETECTION else VU_METER_THRESHOLD
        is_active = dbfs > threshold
        
        # Si enregistrement imm√©diat, toujours enregistrer (optimis√©)
        if IMMEDIATE_RECORDING and self.recording_active:
            # √âviter copy() inutile si on a d√©j√† les bonnes donn√©es
            self.recording_data.append(indata if indata.dtype == np.float32 else indata.astype(np.float32))
        
        if is_active:
            self.last_silence_time = None
            self.silence_start_time = None
            
            # Mode d√©tection classique (si pas d'enregistrement imm√©diat)
            if not IMMEDIATE_RECORDING:
                if self.last_activity_time is None:
                    self.last_activity_time = current_time
                    print(f"üé§ D√©but activit√© d√©tect√©e ({dbfs:.1f} dBFS, seuil: {threshold:.1f})")
                
                if not self.speech_started:
                    activity_duration = current_time - self.last_activity_time
                    if activity_duration >= SPEECH_START_THRESHOLD_SEC:
                        self._start_recording()
                
                if self.recording_active:
                    # Optimiser la copie des donn√©es
                    self.recording_data.append(indata if indata.dtype == np.float32 else indata.astype(np.float32))
            
        else:
            # Silence d√©tect√©
            if self.last_silence_time is None:
                self.last_silence_time = current_time
            
            if self.recording_active:
                # Continuer d'enregistrer le silence pour un r√©sultat naturel (optimis√©)
                self.recording_data.append(indata if indata.dtype == np.float32 else indata.astype(np.float32))
                
                # Mode automatique normal - d√©tection de fin par silence
                silence_timeout = environment_manager.get_silence_duration() if IMMEDIATE_RECORDING else SPEECH_SILENCE_TIMEOUT_MS
                
                if self.silence_start_time is None:
                    self.silence_start_time = current_time
                    print(f"ü§´ Silence d√©tect√©, timeout de {silence_timeout}ms activ√©")
                else:
                    silence_duration = (current_time - self.silence_start_time) * 1000
                    if silence_duration >= silence_timeout:
                        self._on_silence_timeout()
            else:
                # Pas encore en enregistrement (mode classique uniquement)
                if not IMMEDIATE_RECORDING and self.last_activity_time is not None:
                    silence_duration = current_time - self.last_silence_time
                    if silence_duration > (SPEECH_TOLERANCE_MS / 1000.0):
                        print(f"üîÑ Reset timer activit√© apr√®s {silence_duration*1000:.0f}ms de silence")
                        self.last_activity_time = None
    
    def _start_recording(self):
        """D√©marre l'enregistrement effectif"""
        if not self.speech_started:
            self.speech_started = True
            self.recording_active = True
            self.recording_data = []
            print("=" * 50)
            print(f"üî¥ ENREGISTREMENT D√âMARR√â !")
            print(f"üé§ Parlez clairement, silence de {SPEECH_SILENCE_TIMEOUT_MS}ms pour arr√™ter")
            print("=" * 50)
            self.recording_started.emit()
            self.speech_detected.emit()
    
    def _on_silence_timeout(self):
        """Appel√© quand le timeout de silence est atteint"""
        if self.recording_active:
            silence_timeout = environment_manager.get_silence_duration() if IMMEDIATE_RECORDING else SPEECH_SILENCE_TIMEOUT_MS
            print("=" * 50)
            print(f"üîá ARR√äT AUTOMATIQUE (silence de {silence_timeout}ms)")
            print("üíæ Sauvegarde en cours...")
            print("=" * 50)
            self.recording_active = False
            self.silence_detected.emit()
            self.should_stop = True
    
    def _save_recording(self, output_file, samplerate):
        """Sauvegarde l'enregistrement dans un fichier WAV"""
        try:
            if not self.recording_data:
                print("‚ö†Ô∏è Aucune donn√©e √† sauvegarder")
                return
                
            # Concat√©ner toutes les donn√©es
            audio_data = np.concatenate(self.recording_data, axis=0)
            
            # Sauvegarder avec soundfile
            sf.write(output_file, audio_data, samplerate)
            
            duration = len(audio_data) / samplerate
            print(f"üíæ R√©ponse sauvegard√©e: {output_file}")
            print(f"   üìä Dur√©e: {duration:.2f}s, {len(audio_data)} √©chantillons")
            
            self.recording_finished.emit(output_file)
            
        except Exception as e:
            print(f"‚ùå Erreur sauvegarde: {e}")
    
    def stop_recording(self):
        """Arr√™te l'enregistrement imm√©diatement"""
        self.should_stop = True


class AudioPlayer(QThread):
    """Thread pour audio (questions/r√©ponses) - Utilise sounddevice/soundfile"""
    finished = pyqtSignal()
    
    def __init__(self, audio_file):
        super().__init__()
        self.audio_file = audio_file
        self.should_stop = False
        self.stream = None
        
    def run(self):
        try:
            # Utiliser soundfile pour lire le fichier et sounddevice pour jouer
            # Compl√®tement ind√©pendant de pygame
            data, samplerate = sf.read(self.audio_file, dtype='float32')
            
            # Si mono, convertir en st√©r√©o
            if len(data.shape) == 1:
                data = np.column_stack((data, data))
            
            self.current_frame = 0
            total_frames = len(data)
            
            def audio_callback(outdata, frames, time_info, status):
                if self.should_stop:
                    raise sd.CallbackStop()
                
                start = self.current_frame
                end = min(start + frames, total_frames)
                
                if start >= total_frames:
                    # Fin du fichier
                    outdata[:] = 0
                    raise sd.CallbackStop()
                
                # Copier les donn√©es audio
                chunk_size = end - start
                outdata[:chunk_size] = data[start:end]
                
                # Si on n'a pas assez de donn√©es, remplir de z√©ros
                if chunk_size < frames:
                    outdata[chunk_size:] = 0
                
                self.current_frame = end
            
            # D√©marrer le stream sounddevice
            with sd.OutputStream(
                samplerate=samplerate, 
                channels=data.shape[1],
                callback=audio_callback,
                blocksize=1024,
                latency='low'
            ) as self.stream:
                print(f"üé§ Lecture sounddevice: {os.path.basename(self.audio_file)}")
                
                # Attendre que le stream se termine
                while self.stream.active and not self.should_stop:
                    sd.sleep(50)  # Dormir 50ms
                    
        except Exception as e:
            print(f"‚ùå Erreur lecture sounddevice {self.audio_file}: {e}")
        finally:
            self.finished.emit()
    
    def stop(self):
        self.should_stop = True
        if hasattr(self, 'stream') and self.stream:
            try:
                self.stream.abort()
            except:
                pass


class AmbiancePlayer(QThread):
    """Thread d√©di√© EXCLUSIVEMENT pour la musique d'ambiance"""
    
    def __init__(self, audio_file, volume=AMBIANCE_VOLUME):
        super().__init__()
        self.audio_file = audio_file
        self.volume = volume
        self.should_stop = False
        
    def run(self):
        try:
            # pygame.mixer.music N'EST PLUS EN CONFLIT car sounddevice g√®re le reste
            pygame.mixer.music.load(self.audio_file)
            pygame.mixer.music.set_volume(self.volume)
            pygame.mixer.music.play(-1)  # Boucle infinie
            print(f"üéµ Ambiance pygame.music d√©marr√©e: {os.path.basename(self.audio_file)}")
            
            # Surveillance simple
            while not self.should_stop:
                if not pygame.mixer.music.get_busy():
                    print("üéµ Red√©marrage ambiance...")
                    pygame.mixer.music.play(-1)
                pygame.time.wait(500)  # V√©rifier toutes les 500ms
                
        except Exception as e:
            print(f"‚ùå Erreur ambiance: {e}")
    
    def stop(self):
        self.should_stop = True
        try:
            pygame.mixer.music.stop()
            print("üéµ Ambiance arr√™t√©e")
        except:
            pass